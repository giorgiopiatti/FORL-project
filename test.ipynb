{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./ELO_tournament/nocom_models.csv')\n",
    "df2 = df[df['arch'] == 'rnn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from distutils.util import strtobool\n",
    "import copy\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from environment.briscola_communication.actions import BriscolaCommsAction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "\n",
    "class CategoricalMasked(Categorical):\n",
    "    def __init__(self, probs=None, logits=None, validate_args=None, masks=[]):\n",
    "        self.masks = masks\n",
    "        if len(self.masks) == 0:\n",
    "            super(CategoricalMasked, self).__init__(\n",
    "                probs, logits, validate_args)\n",
    "        else:\n",
    "            self.masks = masks.type(torch.BoolTensor).to(logits.device)\n",
    "            logits = torch.where(self.masks, logits,\n",
    "                                 torch.tensor(-1e8).to(logits.device))\n",
    "            super(CategoricalMasked, self).__init__(\n",
    "                probs, logits, validate_args)\n",
    "\n",
    "    def entropy(self):\n",
    "        if len(self.masks) == 0:\n",
    "            return super(CategoricalMasked, self).entropy()\n",
    "        p_log_p = self.logits * self.probs\n",
    "        p_log_p = torch.where(self.masks, p_log_p,\n",
    "                              torch.tensor(0.0).to(self.masks.device))\n",
    "        return -p_log_p.sum(-1)\n",
    "\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, env, rnn_out_size, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            np.prod(env.previous_round_shape), rnn_out_size)\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "            elif \"weight\" in name:\n",
    "                nn.init.orthogonal_(param, 1.0)\n",
    "\n",
    "        self.actor = nn.Sequential(\n",
    "            layer_init(nn.Linear(np.prod(env.current_round_shape) +\n",
    "                       rnn_out_size, hidden_dim)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(hidden_dim, hidden_dim)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(\n",
    "                nn.Linear(hidden_dim, env.num_actions), std=0.01)\n",
    "        )\n",
    "\n",
    "        self.critic = nn.Sequential(\n",
    "            layer_init(nn.Linear(np.prod(env.current_round_shape) +\n",
    "                       rnn_out_size, hidden_dim)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(hidden_dim, hidden_dim)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(hidden_dim, 1), std=1)\n",
    "        )\n",
    "\n",
    "        self.offset_round = env.current_round_shape[-1]\n",
    "\n",
    "    def get_states(self, x, lstm_state, done):\n",
    "        x_features_round = x[:, :, :self.offset_round]  # B, S, F\n",
    "        x_previous_round = x[:, :,  self.offset_round:]    # B, S, P\n",
    "\n",
    "        # LSTM logic\n",
    "        batch_size = lstm_state[0].shape[1]\n",
    "        x_previous_round = x_previous_round.reshape(\n",
    "            (-1, batch_size, self.lstm.input_size))\n",
    "        done = done.reshape((-1, batch_size))\n",
    "\n",
    "        out_lstm = []\n",
    "        for xr, d in zip(x_previous_round, done):\n",
    "            o, lstm_state = self.lstm(\n",
    "                xr.unsqueeze(0),  ((1.0 - d).view(1, -1, 1) * lstm_state[0], (1.0 - d).view(1, -1, 1) * lstm_state[1]))\n",
    "            out_lstm += [o]\n",
    "\n",
    "        out_lstm = torch.flatten(torch.cat(out_lstm), 0, 1)\n",
    "        new_hidden = torch.cat([x_features_round.squeeze(1),\n",
    "                                out_lstm], dim=1)\n",
    "        return new_hidden, lstm_state\n",
    "\n",
    "    def get_value(self, x, lstm_state, done):\n",
    "        hidden, _ = self.get_states(x, lstm_state, done)\n",
    "        return self.critic(hidden)\n",
    "\n",
    "    def get_action_and_value(self, x, action_mask, lstm_state, done, action=None,  deterministic=False):\n",
    "        hidden, lstm_state = self.get_states(x, lstm_state, done)\n",
    "        action_mask = action_mask.squeeze()\n",
    "        logits = self.actor(hidden)\n",
    "        probs = CategoricalMasked(logits=logits, masks=action_mask)\n",
    "        if action is None and not deterministic:\n",
    "            action = probs.sample()\n",
    "        if action is None and deterministic:\n",
    "            if len(action_mask.shape) == 1:\n",
    "                action_mask = action_mask.unsqueeze(0)\n",
    "            logits[~action_mask] = -torch.inf\n",
    "            action = logits.argmax(axis=-1)\n",
    "        return action, probs.log_prob(action), probs.entropy(), self.critic(hidden), lstm_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "num_test_games = 1000\n",
    "num_envs = 16\n",
    "briscola_communicate = False\n",
    "num_steps = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment.briscola_base.briscola_rnn import BriscolaEnv\n",
    "\n",
    "\n",
    "def make_env(seed, rnn_out_size, role_training, briscola_agents, verbose=False, deterministic_eval=False):\n",
    "    def thunk():\n",
    "        # if args.briscola_communicate:\n",
    "        #     env = BriscolaEnv(1, args.rnn_out_size, normalize_reward=False, render_mode='terminal_env' if verbose else None,\n",
    "        #                       role=role_training,  agents=briscola_agents, deterministic_eval=deterministic_eval, device=ENV_DEVICE,\n",
    "        #                       communication_say_truth=briscola_communicate_truth)\n",
    "        # else:\n",
    "        env = BriscolaEnv(1, rnn_out_size, normalize_reward=False, render_mode='terminal_env' if verbose else None,\n",
    "                          role=role_training,  agents=briscola_agents, deterministic_eval=deterministic_eval, device='cpu')\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "        env.seed(seed)\n",
    "        return env\n",
    "\n",
    "    return thunk\n",
    "\n",
    "\n",
    "dummy_env = make_env(42, 0, 'caller', {})()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_elo(modelA_path, modelA_rnn_out_size, modelA_hidden_dim, modelB_path, modelB_rnn_out_size, modelB_hidden_dim):\n",
    "    modelA = Agent(dummy_env, modelA_rnn_out_size, modelA_hidden_dim)\n",
    "    modelA.load_state_dict(torch.load(modelA_path)['model_state_dict'])\n",
    "    modelA.eval()\n",
    "    modelB = Agent(dummy_env, modelB_rnn_out_size, modelB_hidden_dim)\n",
    "    modelB.load_state_dict(torch.load(modelB_path)['model_state_dict'])\n",
    "    modelB.eval()\n",
    "\n",
    "    # 1 Game modelB as caller and callee\n",
    "    config = {'callee': modelB,  'good_1': modelA,\n",
    "              'good_2': modelA, 'good_3': modelA}\n",
    "    env = gym.vector.SyncVectorEnv(\n",
    "        [make_env(seed+(num_envs)+i, modelB_rnn_out_size, 'caller', config, deterministic_eval=True)\n",
    "         for i in range(num_test_games)]\n",
    "    )\n",
    "    data, _ = env.reset()\n",
    "    next_obs, next_mask = torch.tensor(data['observation'],  dtype=torch.float), torch.tensor(\n",
    "        data['action_mask'], dtype=torch.bool)\n",
    "    next_lstm_state = (\n",
    "        torch.zeros(modelB.lstm.num_layers, num_test_games,\n",
    "                    modelB.lstm.hidden_size),\n",
    "        torch.zeros(modelB.lstm.num_layers, num_test_games,\n",
    "                    modelB.lstm.hidden_size),\n",
    "    )  # hidden and cell states\n",
    "    next_done = torch.zeros(num_test_games)\n",
    "\n",
    "    count_truth_comm = 0\n",
    "    for _ in range(0, num_steps):\n",
    "        # ALGO LOGIC: action logic\n",
    "        with torch.no_grad():\n",
    "            action, logprob, _, value, next_lstm_state = modelB.get_action_and_value(\n",
    "                next_obs, next_mask, next_lstm_state, next_done, deterministic=True)\n",
    "            if briscola_communicate and (action >= 40).all():\n",
    "                # Action is communicating\n",
    "                count_truth_comm += (action <\n",
    "                                     (40+BriscolaCommsAction.NUM_MESSAGES)).sum()\n",
    "\n",
    "        # TRY NOT TO MODIFY: execute the game and log data.\n",
    "        data, reward, done, _, info = env.step(action.cpu().numpy())\n",
    "        next_obs, next_mask, next_done = torch.tensor(data['observation'],  dtype=torch.float), torch.tensor(\n",
    "            data['action_mask'], dtype=torch.bool), torch.tensor(done, dtype=torch.float)\n",
    "\n",
    "    reward_bad_B = reward.mean()\n",
    "    reward_good_A = 120.0-reward_bad_B\n",
    "\n",
    "    # 2 Game\n",
    "    config = {'callee': modelA,  'caller': modelA,\n",
    "              'good_2': modelB, 'good_3': modelB}\n",
    "    env = gym.vector.SyncVectorEnv(\n",
    "        [make_env(seed+(num_envs)+i, modelB_rnn_out_size, 'good_1', config, deterministic_eval=True)\n",
    "         for i in range(num_test_games)]\n",
    "    )\n",
    "    data, _ = env.reset()\n",
    "    next_obs, next_mask = torch.tensor(data['observation'],  dtype=torch.float), torch.tensor(\n",
    "        data['action_mask'], dtype=torch.bool)\n",
    "    next_lstm_state = (\n",
    "        torch.zeros(modelB.lstm.num_layers, num_test_games,\n",
    "                    modelB.lstm.hidden_size),\n",
    "        torch.zeros(modelB.lstm.num_layers, num_test_games,\n",
    "                    modelB.lstm.hidden_size),\n",
    "    )  # hidden and cell states\n",
    "    next_done = torch.zeros(num_test_games)\n",
    "\n",
    "    count_truth_comm = 0\n",
    "    for _ in range(0, num_steps):\n",
    "        # ALGO LOGIC: action logic\n",
    "        with torch.no_grad():\n",
    "            action, logprob, _, value, next_lstm_state = modelB.get_action_and_value(\n",
    "                next_obs, next_mask, next_lstm_state, next_done, deterministic=True)\n",
    "            if briscola_communicate and (action >= 40).all():\n",
    "                # Action is communicating\n",
    "                count_truth_comm += (action <\n",
    "                                     (40+BriscolaCommsAction.NUM_MESSAGES)).sum()\n",
    "\n",
    "        # TRY NOT TO MODIFY: execute the game and log data.\n",
    "        data, reward, done, _, info = env.step(action.cpu().numpy())\n",
    "        next_obs, next_mask, next_done = torch.tensor(data['observation'],  dtype=torch.float), torch.tensor(\n",
    "            data['action_mask'], dtype=torch.bool), torch.tensor(done, dtype=torch.float)\n",
    "\n",
    "    reward_good_B = reward.mean()\n",
    "    reward_bad_A = 120.0-reward_good_B\n",
    "\n",
    "    return reward_bad_A, reward_good_A, reward_bad_B, reward_good_B,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gio/ETH-Code/forl-project/environment/briscola_base/briscola_rnn.py:154: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode.\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(84.402, 31.189999999999998, 88.81, 35.598)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelA_path = f\"./ELO_tournament/nocom/{df2.iloc[20]['file_name']}\"\n",
    "modelA_rnn_out_size = df2.iloc[20]['rnn_out_size']\n",
    "modelA_hidden_dim = df2.iloc[20]['hidden_dim']\n",
    "modelB_path = f\"./ELO_tournament/nocom/{df2.iloc[21]['file_name']}\"\n",
    "modelB_rnn_out_size = df2.iloc[21]['rnn_out_size']\n",
    "modelB_hidden_dim = df2.iloc[21]['hidden_dim']\n",
    "\n",
    "evaluate_elo(modelA_path, modelA_rnn_out_size, modelA_hidden_dim, modelB_path, modelB_rnn_out_size, modelB_hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>arch</th>\n",
       "      <th>comm</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>rnn_out_size</th>\n",
       "      <th>step</th>\n",
       "      <th>last</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>P2_PPO_universal_RNN_h=128_rnn=128__1__1685970630</td>\n",
       "      <td>95o6x1dd</td>\n",
       "      <td>rnn</td>\n",
       "      <td>nocom</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>12800000</td>\n",
       "      <td>False</td>\n",
       "      <td>95o6x1dd_12800000.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>P2_PPO_universal_RNN_h=128_rnn=128__1__1685970630</td>\n",
       "      <td>95o6x1dd</td>\n",
       "      <td>rnn</td>\n",
       "      <td>nocom</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>25600000</td>\n",
       "      <td>False</td>\n",
       "      <td>95o6x1dd_25600000.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>P2_PPO_universal_RNN_h=128_rnn=128__1__1685970630</td>\n",
       "      <td>95o6x1dd</td>\n",
       "      <td>rnn</td>\n",
       "      <td>nocom</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>38400000</td>\n",
       "      <td>False</td>\n",
       "      <td>95o6x1dd_38400000.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>P2_PPO_universal_RNN_h=128_rnn=128__1__1685970630</td>\n",
       "      <td>95o6x1dd</td>\n",
       "      <td>rnn</td>\n",
       "      <td>nocom</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>51200000</td>\n",
       "      <td>False</td>\n",
       "      <td>95o6x1dd_51200000.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>P2_PPO_universal_RNN_h=128_rnn=64__1__1685970621</td>\n",
       "      <td>jgfgmbkg</td>\n",
       "      <td>rnn</td>\n",
       "      <td>nocom</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>12800000</td>\n",
       "      <td>False</td>\n",
       "      <td>jgfgmbkg_12800000.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>T_PPO_universal_RNN_h=64_rnn=64__1__1685745066</td>\n",
       "      <td>p7d4raf4</td>\n",
       "      <td>rnn</td>\n",
       "      <td>nocom</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>38400000</td>\n",
       "      <td>False</td>\n",
       "      <td>p7d4raf4_38400000.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>T_PPO_universal_RNN_h=64_rnn=64__1__1685745066</td>\n",
       "      <td>p7d4raf4</td>\n",
       "      <td>rnn</td>\n",
       "      <td>nocom</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>51200000</td>\n",
       "      <td>False</td>\n",
       "      <td>p7d4raf4_51200000.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>T_PPO_universal_RNN_h=64_rnn=64__1__1685745066</td>\n",
       "      <td>p7d4raf4</td>\n",
       "      <td>rnn</td>\n",
       "      <td>nocom</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64000000</td>\n",
       "      <td>False</td>\n",
       "      <td>p7d4raf4_64000000.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>T_PPO_universal_RNN_h=64_rnn=64__1__1685745066</td>\n",
       "      <td>p7d4raf4</td>\n",
       "      <td>rnn</td>\n",
       "      <td>nocom</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>76800000</td>\n",
       "      <td>False</td>\n",
       "      <td>p7d4raf4_76800000.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>T_PPO_universal_RNN_h=64_rnn=64__1__1685745066</td>\n",
       "      <td>p7d4raf4</td>\n",
       "      <td>rnn</td>\n",
       "      <td>nocom</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>80000000</td>\n",
       "      <td>True</td>\n",
       "      <td>p7d4raf4_80000000.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               name        id   \n",
       "23           0  P2_PPO_universal_RNN_h=128_rnn=128__1__1685970630  95o6x1dd  \\\n",
       "24           0  P2_PPO_universal_RNN_h=128_rnn=128__1__1685970630  95o6x1dd   \n",
       "25           0  P2_PPO_universal_RNN_h=128_rnn=128__1__1685970630  95o6x1dd   \n",
       "26           0  P2_PPO_universal_RNN_h=128_rnn=128__1__1685970630  95o6x1dd   \n",
       "27           0   P2_PPO_universal_RNN_h=128_rnn=64__1__1685970621  jgfgmbkg   \n",
       "..         ...                                                ...       ...   \n",
       "92           0     T_PPO_universal_RNN_h=64_rnn=64__1__1685745066  p7d4raf4   \n",
       "93           0     T_PPO_universal_RNN_h=64_rnn=64__1__1685745066  p7d4raf4   \n",
       "94           0     T_PPO_universal_RNN_h=64_rnn=64__1__1685745066  p7d4raf4   \n",
       "95           0     T_PPO_universal_RNN_h=64_rnn=64__1__1685745066  p7d4raf4   \n",
       "96           0     T_PPO_universal_RNN_h=64_rnn=64__1__1685745066  p7d4raf4   \n",
       "\n",
       "   arch   comm  hidden_dim  rnn_out_size      step   last   \n",
       "23  rnn  nocom         128           128  12800000  False  \\\n",
       "24  rnn  nocom         128           128  25600000  False   \n",
       "25  rnn  nocom         128           128  38400000  False   \n",
       "26  rnn  nocom         128           128  51200000  False   \n",
       "27  rnn  nocom         128            64  12800000  False   \n",
       "..  ...    ...         ...           ...       ...    ...   \n",
       "92  rnn  nocom          64            64  38400000  False   \n",
       "93  rnn  nocom          64            64  51200000  False   \n",
       "94  rnn  nocom          64            64  64000000  False   \n",
       "95  rnn  nocom          64            64  76800000  False   \n",
       "96  rnn  nocom          64            64  80000000   True   \n",
       "\n",
       "               file_name  \n",
       "23  95o6x1dd_12800000.pt  \n",
       "24  95o6x1dd_25600000.pt  \n",
       "25  95o6x1dd_38400000.pt  \n",
       "26  95o6x1dd_51200000.pt  \n",
       "27  jgfgmbkg_12800000.pt  \n",
       "..                   ...  \n",
       "92  p7d4raf4_38400000.pt  \n",
       "93  p7d4raf4_51200000.pt  \n",
       "94  p7d4raf4_64000000.pt  \n",
       "95  p7d4raf4_76800000.pt  \n",
       "96  p7d4raf4_80000000.pt  \n",
       "\n",
       "[74 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
